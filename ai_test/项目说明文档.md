# AiProtect —— AI 驱动的智能测试平台

## 一、项目概述

AiProtect 是一款基于大语言模型（LLM）和智能体（Agent）技术打造的 **AI 驱动智能测试平台**，旨在通过 AI 能力深度融合软件测试全流程，实现测试用例的自动生成、自动执行、智能管理和团队协作，大幅提升测试效率与质量。

---

## 二、解决什么问题

### 2.1 传统测试面临的痛点

| 痛点 | 描述 |
|------|------|
| **用例编写耗时** | 手工编写功能测试用例需要大量时间，且容易遗漏边界场景和异常场景，覆盖率难以保证 |
| **接口测试门槛高** | 接口自动化测试需要测试人员具备编程能力，编写和维护接口用例成本高 |
| **用例维护困难** | 随着需求迭代，测试用例需要频繁更新，手工维护效率低下 |
| **测试覆盖率不足** | 人工设计用例容易产生思维盲区，难以系统性覆盖所有测试点 |
| **UI 自动化成本高** | UI 自动化测试脚本编写复杂，页面变动后维护成本极大 |
| **知识经验难传承** | 测试经验依赖个人，人员变动导致测试质量波动 |
| **排期进度不透明** | 测试排期依赖手动维护 Excel/飞书表格，信息分散，leader 需频繁询问进度，效率低下 |
| **进度同步多方低效** | 一个项目的进展要同步到项目群/需求表/leader 等多方，重复沟通消耗大量时间 |

### 2.2 AiProtect 如何解决

- **AI 自动生成测试用例**：基于需求文档 / 接口文档，由 AI 自动提取测试点、生成覆盖完整的功能测试用例和接口测试用例，消除人工编写的遗漏和低效
- **AI 智能提取需求信息**：支持上传 PDF/DOCX/HTML 文件或粘贴文本，AI 自动从文档中提取结构化需求描述，减少人工整理需求的时间
- **AI 智能执行与验证**：AI 不仅生成用例，还能自动执行接口测试并验证结果，实现"需求 → 用例 → 执行 → 报告"的全链路自动化
- **XMind 用例导出**：生成的测试用例可一键导出为 XMind 思维导图文件，支持自定义模板格式、节点属性标注，方便线下评审和分享
- **知识库驱动的测试设计**：通过 RAG（检索增强生成）技术将需求文档、接口文档沉淀为知识库，AI 基于知识库进行精准的用例生成
- **覆盖率闭环保障**：工作流中内置覆盖率验证节点，自动检查生成的测试点和用例是否覆盖全部需求，未覆盖则自动补充
- **测试排期数字化**：将传统的飞书/Excel 手动排期转移到平台内管理，支持迭代管理、需求排期分配、进度跟踪
- **AI 智能进度报告**：AI 根据排期数据、完成百分比、风险评估自动生成进度报告，一键同步到飞书群，替代手动写报告
- **业务线权限管理**：基于业务线维度的人员分配和数据隔离，测试人员默认只看自己业务线的排期，管理员可查看全局

---

## 三、核心功能模块

### 3.1 功能用例生成

**功能描述**：基于需求文档，利用 AI 自动生成功能测试用例。

**工作流程**：

```
需求文档 → [提取测试点] → [验证测试点覆盖率] → (未覆盖？补充测试点) 
        → [生成测试用例] → [验证用例覆盖率] → (未覆盖？补充用例) → [保存到数据库]
```

**技术实现**：
- 使用 **LangGraph** 构建状态机工作流（`GeneratorTestCaseWorkflow`），包含子工作流 `GeneratorPointWorkflow`
- **子工作流**：需求文档 → 测试点提取 → 覆盖率验证 → 循环补充直至 100% 覆盖
- **主工作流**：测试点 → 测试用例生成 → 用例覆盖率验证 → 循环补充直至全部覆盖 → 保存到数据库
- 前端通过 **SSE（Server-Sent Events）** 实时展示 AI 生成过程，支持 ChatGPT 风格的流式输出
- 生成的用例自动保存到 `functional_case` 表，关联对应需求

**AI Agent 工具链**：
- `search_requirement`：从 RAG 知识库检索需求文档
- `generator_case`：调用用例生成工作流

### 3.2 AI 智能提取需求信息

**功能描述**：支持用户上传需求文档文件或粘贴文本，AI 自动从中提取结构化的需求描述信息，减少人工整理需求的工作量。

**支持的输入方式**：
- **文件上传**：支持 PDF、DOCX、HTML 等格式的需求文档
- **文本粘贴**：直接粘贴需求文本内容（适用于飞书云文档等无法直接抓取的场景）

**技术实现**：
- **文档解析**：使用 `pdfplumber`（PDF）、`python-docx`（DOCX）、`beautifulsoup4`（HTML）提取文本内容
- **AI 结构化提取**：使用 LLM（Claude / GPT）基于精心设计的 Prompt 模板，从非结构化文本中提取需求标题、需求描述、前置条件、功能点列表等结构化信息
- **配置灵活**：支持通过环境变量配置 LLM 模型（`LLM_MODEL`）、API 地址（`BASE_URL`）和密钥（`API_KEY`），兼容 OpenAI 兼容接口（如 Litellm 代理）

### 3.3 XMind 用例导出

**功能描述**：将 AI 生成的功能测试用例导出为 XMind 思维导图文件，方便线下评审、团队分享和外部使用。

**功能特性**：
- **自定义模板**：导出前可预览和配置 XMind 结构格式
- **节点属性标注**：可配置是否在节点中注明"前置条件"、"测试步骤"、"预期结果"等属性标签前缀
- **嵌套结构**：前置条件 → 测试步骤 → 预期结果层层嵌套，结构清晰
- **优先级标注**：用例标题前自动注明优先级（P0/P1/P2/P3）
- **编号列表换行**：每个子节点内的多个步骤自动换行显示，阅读性好

**技术实现**：
- 使用 Python 标准库 `zipfile` + `json` 生成 XMind 8+ 格式文件（`.xmind` 本质上是 ZIP 包含 `content.json`）
- 后端 API 直接返回文件流，前端以 Blob 方式下载

### 3.4 AI 执行用例

**功能描述**：AI 生成的接口测试用例可直接自动执行，支持单用例执行、测试套件执行、测试任务执行三种粒度。

**执行层级**：

```
测试任务 (Task) 
  └── 测试套件 (Suite) 
        └── 测试用例 (Case) → 执行引擎 → 执行结果 & 报告
```

**技术实现**：
- **执行引擎**（`TestExecutor`）：
  - 支持前置依赖接口的自动调用和数据提取
  - 支持前后置脚本（Python `exec` 动态执行）
  - 支持变量替换（`${{变量名}}` 语法引用测试环境数据）
  - 支持多种请求格式（JSON、Form、XML、文件上传）
  - 支持多种断言方式（HTTP 状态码、字段值相等、非空校验等，基于 JMESPath 表达式提取）
  - 支持数据库校验（连接被测系统数据库进行数据验证）
- **执行模式**：
  - 同步执行：单用例/套件实时返回结果
  - **后台异步执行**：测试任务通过 FastAPI `BackgroundTasks` 后台执行，前端轮询查看执行状态
- **结果记录**：每次执行的结果（状态、日志、请求/响应数据、耗时等）持久化到数据库，支持历史记录查询和执行报告

### 3.5 接口用例生成 & 接口自动化

**功能描述**：基于接口文档（OpenAPI / Swagger），AI 自动生成基础测试用例，再进一步生成可直接执行的接口自动化用例。

**工作流程**：

```
接口文档 → [生成基础用例] → [验证覆盖率] → (未覆盖？补充用例)
        → [遍历基础用例] → [生成可执行用例] → [预执行验证] → (失败？重新生成) → [保存到数据库]
```

**技术实现**：
- **第一阶段 - 基础用例生成**（`ApiBaseCaseGeneratorWorkFlow`）：
  - AI 基于接口文档分析接口的功能点和测试场景
  - 自动生成基础用例（包含用例名称、测试步骤、预期结果、前置依赖）
  - 内置覆盖率验证，未达 100% 自动补充生成
- **第二阶段 - 可执行用例生成**（`ApiRunCaseGeneratorWorkFlow`）：
  - 加载可用的工具函数列表和测试文件列表
  - AI 基于基础用例和测试环境配置，生成包含完整请求数据（URL、Headers、Body、Params）、断言规则的结构化可执行用例
  - **预执行验证**：自动执行生成的用例，验证其可用性；执行失败则重新生成（最多 3 次）
  - 验证通过后保存到数据库，标记为 `ready` 状态
- **接口文档解析**（`utils/parser`）：支持 OpenAPI 3.0 和 Swagger 2.0 格式的接口文档解析，提取接口路径、方法、参数、请求体、响应体等结构化信息
- **RAG 知识库**：通过 LightRAG + RAGAnything 将接口文档存入知识库，支持多模态文档（含图片、表格），Agent 可以通过自然语言检索接口信息
- **多 Agent 协作**（`AgentManage`）：
  - `case_generator_agent`：功能用例生成智能体
  - `api_case_generator_agent`：接口用例生成智能体
  - `supervisor`：主管 Agent，根据用户意图路由到对应的子 Agent

### 3.6 测试排期管理

**功能描述**：将传统的飞书/Excel 手动排期管理数字化，集成到 AI 测试平台中，实现迭代管理、需求排期分配和进度跟踪的一体化。

**核心功能**：
- **迭代管理**：创建和管理测试迭代（如"Sprint 25"），设置迭代周期和状态（规划中/进行中/已完成）
- **需求排期**：在迭代中添加需求排期项，分配负责人、设置计划时间、关联业务线、跟踪完成进度
- **测试日报**：测试人员提交当日各需求的进度更新，支持 AI 一键生成日报内容
- **进度看板**：
  - **当日动态**：管理员查看各需求的最新进度
  - **迭代汇总**：按迭代维度汇总所有需求的整体进度、风险评估
- **数据权限**：基于业务线归属控制编辑权限，同业务线成员可互相编辑排期

**技术实现**：
- 后端使用 Tortoise ORM 管理 `TestIteration`、`ScheduleItem`、`DailyReport`、`ProgressReport` 等数据模型
- 前端四大页面：迭代管理（排期表格）、测试日报（提交与历史）、进度看板（统计卡片 + 数据表）、飞书配置
- 前端使用 `vuedraggable` 实现快捷入口拖拽排序

### 3.7 AI 智能进度报告

**功能描述**：AI 根据排期数据、完成百分比、Bug 缺陷情况自动生成测试进度报告，并支持一键推送到飞书群。

**报告类型**：
- **测试人员视角**：针对当日处理的需求生成进度报告
- **管理员视角**：
  - 当日各需求的进度汇总
  - 迭代中期的整体进度汇总
  - 迭代末期带风险评估的进度报告

**飞书集成**：
- 支持配置飞书 Webhook 地址
- AI 生成的报告以飞书互动卡片形式推送到指定群
- 报告内容包含：需求名称、负责人、计划时间、完成进度、风险等级、当日更新等

**技术实现**：
- AI 报告生成使用 LLM Prompt 分析排期数据，输出结构化报告
- 飞书推送使用 `httpx` 异步发送 Webhook 请求，构造飞书互动卡片 JSON
- 后端支持报告存储和历史查询

### 3.8 业务线管理 & 权限体系

**功能描述**：基于业务线维度管理测试团队，支持树形业务线结构、人员分配和细粒度的数据权限控制。

**核心功能**：
- **业务线树形结构**：支持父子层级关系的业务线管理（如"支付业务线 → 退款"、"商品业务线 → SKU管理"）
- **人员分配**：管理员可将测试人员分配到业务线，设置角色（管理员/组长/成员）
- **跨业务线支援**：人员以一个主业务线为主，也可临时支援其他业务线的需求

**权限体系（RBAC）**：

| 角色 | 权限说明 |
|------|---------|
| **管理员** | 全部功能可用，包括项目管理、业务线管理、迭代创建等 |
| **组长** | 可查看全部数据，可编辑本业务线排期，可添加需求排期 |
| **测试人员** | 可查看全部数据，默认筛选本业务线，可编辑本业务线排期 |

**菜单权限**：
- **项目管理**（业务线管理、成员管理等）：仅管理员可见
- **排期管理**：全员可见
- **新建迭代**：仅管理员可操作

**技术实现**：
- 后端 `BusinessLineMember` 模型维护用户与业务线的关联关系
- `verify_schedule_access` 权限校验函数支持管理员 + 项目成员 + 业务线成员三级校验
- 前端通过 `userStore.user.is_superuser` 控制菜单和按钮的显示/隐藏
- 前端路由 `meta.requiresAdmin` 控制页面级别访问权限

### 3.9 UI 自动化（开发中）

**功能描述**：基于页面对象模型（Page Object Model），管理 UI 测试页面和 UI 测试用例，支持 UI 自动化测试。

**当前状态**：功能模块已搭建（页面管理、用例管理），核心自动化执行能力正在由其他团队成员开发中。

**规划能力**：
- UI 页面元素管理和维护
- 基于页面对象模型的 UI 测试用例设计
- AI 辅助生成 UI 自动化测试脚本
- UI 自动化执行与结果报告

---

## 四、技术方案

### 4.1 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                        前端 (Vue 3)                          │
│  Element Plus + Vue Router + Pinia + ECharts + CodeMirror   │
│  Vite 构建  |  SSE 流式交互  |  vuedraggable 拖拽排序        │
└──────────────────────────┬──────────────────────────────────┘
                           │  Nginx 反向代理
┌──────────────────────────▼──────────────────────────────────┐
│                    后端 (FastAPI + Python 3.11)               │
│                                                              │
│  ┌──────────────┐  ┌──────────────┐  ┌───────────────────┐  │
│  │  业务服务层    │  │  AI 智能体层  │  │  工作流引擎层      │  │
│  │              │  │              │  │                   │  │
│  │ - 用户管理    │  │ - 功能用例    │  │ - 测试点生成工作流  │  │
│  │ - 项目管理    │  │   生成 Agent  │  │ - 功能用例生成工作流│  │
│  │ - 业务线管理  │  │ - 接口用例    │  │ - 基础用例生成工作流│  │
│  │ - 功能测试    │  │   生成 Agent  │  │ - 可执行用例生成   │  │
│  │ - 接口测试    │  │ - Supervisor  │  │   工作流           │  │
│  │ - 测试管理    │  │   多Agent协作  │  │ - 覆盖率验证工作流  │  │
│  │ - 排期管理    │  │ - AI进度报告   │  │                   │  │
│  │ - 智能报告    │  │   生成         │  │                   │  │
│  └──────────────┘  └──────────────┘  └───────────────────┘  │
│                                                              │
│  ┌──────────────┐  ┌──────────────┐  ┌───────────────────┐  │
│  │  RAG 知识库   │  │  用例执行引擎 │  │   MCP 工具服务     │  │
│  │              │  │              │  │                   │  │
│  │ - LightRAG   │  │ - HTTP 请求   │  │ - 需求检索        │  │
│  │ - RAGAnything │  │ - 变量替换    │  │ - 用例生成        │  │
│  │ - Embedding   │  │ - 脚本执行    │  │ - 接口文档检索     │  │
│  │ - Rerank      │  │ - 断言验证    │  │ - 环境数据加载     │  │
│  │ - 多模态理解   │  │ - 数据库校验  │  │                   │  │
│  └──────────────┘  └──────────────┘  └───────────────────┘  │
│                                                              │
│  ┌──────────────────────────────────────────────────────────┐│
│  │                   权限与安全层                             ││
│  │  JWT认证 | RBAC权限(管理员/组长/成员) | 业务线数据隔离      ││
│  └──────────────────────────────────────────────────────────┘│
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────▼──────────────────────────────────┐
│                     数据与基础设施层                           │
│                                                              │
│  MySQL 8.0 (Tortoise ORM)  |  LangSmith (可观测性)           │
│  Docker Compose 容器化部署   |  Gunicorn + Uvicorn (部署)     │
│  飞书 Webhook 集成           |  Nginx (反向代理 + 静态服务)    │
└─────────────────────────────────────────────────────────────┘
```

### 4.2 技术栈明细

| 层级 | 技术 | 说明 |
|------|------|------|
| **前端** | Vue 3 + Vite 7 | 现代化 SPA 前端框架 |
| | Element Plus | UI 组件库 |
| | Pinia | 状态管理 |
| | Vue Router | 前端路由（含路由守卫权限控制） |
| | ECharts | 数据可视化（测试报告图表） |
| | CodeMirror / Monaco Editor | 代码编辑器（脚本编写、JSON 编辑） |
| | Axios + SSE | HTTP 请求与流式数据交互 |
| | vuedraggable | 拖拽排序（快捷入口配置） |
| **后端** | Python 3.11 + FastAPI | 高性能异步 Web 框架 |
| | Tortoise ORM + MySQL 8 | 异步 ORM 数据库访问 |
| | Gunicorn + Uvicorn | 生产级 ASGI 服务器（timeout=180s） |
| | PyJWT + Bcrypt | JWT 认证（3天有效期）与密码加密 |
| | httpx | 异步 HTTP 客户端（飞书 Webhook 推送） |
| | pdfplumber / python-docx / beautifulsoup4 | 文档解析（PDF/DOCX/HTML） |
| **AI / LLM** | LangChain + LangGraph | LLM 应用框架与工作流编排 |
| | LangGraph Supervisor | 多 Agent 协作框架 |
| | LangSmith | LLM 调用可观测性与调试 |
| | LightRAG + RAGAnything | RAG 知识库（支持多模态文档） |
| | OpenAI 兼容接口 | 支持 Claude / GPT 等模型（通过 Litellm 代理） |
| **测试执行** | Requests + JMESPath | HTTP 请求发送与响应数据提取 |
| | Faker | 随机测试数据生成 |
| | PyMySQL | 数据库连接与验证 |
| | Allure + Pytest | 测试报告生成 |
| **部署** | Docker + Docker Compose | 容器化一键部署 |
| | Nginx | 静态文件服务 + API 反向代理（client_max_body_size=20m） |

### 4.3 数据模型

```
项目 (Project)
  ├── 业务线/模块 (ProjectModule) ── 支持树形父子结构
  │     └── 业务线成员 (BusinessLineMember) ── 角色：admin/lead/member
  ├── 成员 (ProjectMember)
  ├── 测试环境 (TestEnvironment)
  │     ├── 环境变量 (TestEnvironmentConfig)
  │     └── 数据库配置 (TestEnvironmentDb)
  ├── 功能测试
  │     ├── 需求 (Requirement)
  │     └── 功能用例 (FunctionalCase)
  ├── 接口测试
  │     ├── 接口 (Interface)
  │     ├── 基础用例 (ApiBaseCase)
  │     ├── 接口测试用例 (ApiTestCase)
  │     └── 接口依赖 (DependencyGroup / DependencyItem)
  ├── 测试管理 & 执行
  │     ├── 测试任务 (TestTask) ── 支持 functional/api/ui 类型
  │     ├── 测试套件 (TestSuite)
  │     ├── 任务-套件关联 (TaskSuiteRelation)
  │     ├── 套件-用例关联 (SuiteCaseRelation)
  │     ├── 任务运行记录 (TestTaskRun)
  │     ├── 套件运行记录 (TestSuiteRun)
  │     └── 用例运行记录 (ApiCaseRun)
  └── 排期管理
        ├── 测试迭代 (TestIteration)
        ├── 需求排期 (ScheduleItem)
        ├── 测试日报 (DailyReport)
        ├── 进度报告 (ProgressReport)
        └── 飞书 Webhook (FeishuWebhook)
```

### 4.4 AI 工作流设计亮点

1. **覆盖率闭环验证**：每个工作流都内置覆盖率验证节点，AI 生成的测试点/用例必须通过覆盖率审查，未通过则自动循环补充，确保质量
2. **预执行验证机制**：接口用例生成后自动预执行，验证用例可用性，不可用则重新生成（最多 3 次重试），确保生成的用例是真正可执行的
3. **子工作流嵌套**：通过 LangGraph 的子图（Subgraph）机制实现工作流嵌套，如主工作流调用测试点生成子工作流，结构清晰可维护
4. **流式输出体验**：全程基于 SSE 流式推送 AI 生成进度，前端以 ChatGPT 风格实时展示，用户体验流畅
5. **多 Agent 协作**：通过 Supervisor 模式实现多 Agent 协作，用户只需自然语言描述需求，系统自动路由到合适的 Agent 处理
6. **AI 进度报告生成**：LLM 分析排期数据和完成进度，自动生成带风险评估的结构化进度报告，减少人工撰写报告的工作量

---

## 五、业务价值说明

### 5.1 效率提升

| 场景 | 传统方式 | 使用 AiProtect | 提升倍率 |
|------|---------|----------------|---------|
| 功能用例编写 | 1 个中等需求约 2-4 小时 | AI 自动生成约 2-5 分钟 | **约 30-50 倍** |
| 需求信息整理 | 阅读文档手工提取约 30-60 分钟 | AI 自动提取约 1-2 分钟 | **约 20-30 倍** |
| 接口用例设计 | 1 个接口约 1-2 小时 | AI 自动生成约 1-3 分钟 | **约 30-40 倍** |
| 接口自动化脚本 | 1 个接口约 2-4 小时 | AI 生成可执行用例约 3-5 分钟 | **约 40-50 倍** |
| 回归测试执行 | 人工执行半天到 1 天 | 自动化执行数分钟 | **约 100+ 倍** |
| 测试进度报告 | 手动整理排期表写报告 30-60 分钟 | AI 一键生成并推送 1 分钟 | **约 30-60 倍** |
| 排期维护同步 | 多平台手动更新（飞书表/群消息/邮件） | 平台统一管理 + 飞书一键推送 | **减少 80% 沟通成本** |

### 5.2 质量保障

- **更高的覆盖率**：AI 系统化分析需求/接口文档，结合覆盖率验证循环，覆盖率显著高于人工设计
- **减少人为遗漏**：AI 不会"遗忘"边界场景和异常场景，确保测试完整性
- **用例可用性保障**：接口用例经过预执行验证，确保生成即可用，避免"只能看不能跑"的尴尬
- **标准化输出**：AI 生成的用例格式统一、规范，便于团队协作和审查
- **XMind 可视化评审**：一键导出思维导图，方便用例评审和分享，提高评审效率

### 5.3 成本节约

- **降低人力成本**：AI 承担大量重复性的测试设计和编写工作，测试团队可聚焦于更高价值的探索性测试和策略制定
- **缩短交付周期**：测试准备时间大幅缩短，加速项目交付节奏
- **降低技术门槛**：不需要测试人员具备编程能力即可获得接口自动化用例，降低团队技术门槛
- **减少维护成本**：需求变更时只需重新触发 AI 生成，无需人工逐条修改用例
- **减少沟通成本**：排期和进度信息数字化管理，AI 自动生成报告并推送，减少人工同步

### 5.4 知识沉淀

- **需求文档知识化**：通过 RAG 将需求文档和接口文档沉淀为可检索的知识库，测试设计不再依赖个人记忆
- **测试经验标准化**：AI 的提示词（Prompt）中内置了测试设计的最佳实践，确保每次生成都符合专业标准
- **可追溯的测试历史**：所有执行记录、测试报告持久化存储，支持回溯和分析
- **排期数据积累**：迭代排期和进度数据持续积累，为未来的资源规划和效率分析提供数据基础

### 5.5 团队赋能

- **项目级管理**：支持多项目管理，每个项目独立的模块、成员、环境配置
- **业务线管理**：树形业务线结构，人员归属清晰，数据隔离有序
- **角色权限控制**：管理员、组长、测试人员三级权限，菜单级 + 数据级 + 操作级细粒度控制
- **测试资产管理**：测试计划、测试套件、测试用例全生命周期管理
- **可视化测试报告**：任务/套件级执行报告，支持通过/失败/错误/跳过等多维度统计
- **可配置化仪表盘**：快捷入口支持自定义配置和拖拽排序，适配不同用户使用习惯
- **飞书生态集成**：测试进度报告一键推送到飞书群，减少多平台切换

---

## 六、项目结构

```
ai/ai_test/
├── backend/                    # 后端服务
│   ├── main.py                 # FastAPI 应用入口
│   ├── gunicorn.py             # Gunicorn 配置（timeout=180s）
│   ├── agents/                 # AI 智能体（多 Agent 协作）
│   ├── workflow/               # LangGraph 工作流
│   │   ├── case_generator_workflow.py          # 功能用例生成工作流
│   │   ├── api_basecase_workflow.py            # 接口基础用例生成工作流
│   │   ├── api_case_generator_main_workflow.py # 接口用例生成主工作流
│   │   └── api_run_case_wrokflow.py            # 可执行用例生成工作流
│   ├── mcp_tools/              # AI Agent 工具集
│   ├── rag/                    # RAG 知识库管理
│   ├── api_case_run/           # 接口用例执行引擎
│   ├── config/                 # 配置与提示词
│   │   ├── settings.py         # 大模型配置（LLM_MODEL / BASE_URL / API_KEY）
│   │   └── prompts/            # 各环节的 Prompt 模板
│   │         └── parser/       # 需求提取 Prompt
│   ├── service/                # 业务服务模块
│   │   ├── user/               # 用户管理
│   │   ├── project/            # 项目管理 & 业务线管理 & 成员分配
│   │   ├── test_environment/   # 测试环境
│   │   ├── functional_test/    # 功能测试（含AI需求提取 & XMind导出）
│   │   ├── api_test/           # 接口测试
│   │   ├── test_management/    # 测试管理
│   │   ├── test_execution/     # 测试执行
│   │   └── schedule/           # 排期管理 & 进度报告 & 飞书集成
│   └── utils/                  # 工具类
│         ├── auth.py           # JWT 认证
│         ├── permissions.py    # RBAC 权限校验
│         ├── xmind_generator.py # XMind 文件生成
│         └── parser/           # 文档解析（PDF/DOCX/HTML）
├── frontend/                   # 前端应用
│   └── src/
│       ├── api/                # API 服务层
│       │   ├── schedule.js     # 排期管理 API
│       │   ├── module.js       # 业务线管理 API
│       │   └── functional_test.js # 功能测试 API（含XMind导出）
│       ├── components/
│       │   └── Layout.vue      # 主布局（含权限控制的侧边栏）
│       ├── stores/             # Pinia 状态管理
│       └── views/
│           ├── ApiTest/        # 接口测试（管理、用例、生成、执行）
│           ├── FunctionTest/   # 功能测试（需求、用例、AI 生成、XMind导出）
│           ├── UiTest/         # UI 自动化（开发中）
│           ├── Schedule/       # 排期管理（迭代、日报、看板、飞书）
│           ├── ProjectSettings/# 项目设置（仪表盘、业务线管理、成员）
│           ├── ComingSoon/     # 未来可期（功能规划展示）
│           └── TestExecution/  # 测试执行报告
├── nginx/                      # Nginx 配置
├── docker-compose.yml          # Docker 编排
└── prd/                        # 示例需求文档
```

---

## 七、快速开始

### Docker 一键部署

```bash
cd ai/ai_test
docker-compose up -d --build
```

启动后访问：
- 前端页面：`http://localhost:5002`
- 接口文档：`http://localhost:5002/api/swagger`
- 默认管理员账号：`admin` / `123456`

### 本地开发

```bash
# 后端
cd backend
pip install -r requirements.txt
python main.py

# 前端
cd frontend
npm install
npm run dev
```

### 环境变量配置

后端 AI 模型配置（`backend/.env`）：
```env
LLM_MODEL=bedrock-claude-4-5-sonnet
BASE_URL=https://your-litellm-proxy/chat/completions
API_KEY=your-api-key
```

---

> **注意**：本项目的 UI 自动化执行能力及部分其他功能正在由团队其他成员同步开发中，本文档描述的是当前代码仓库中已实现的核心功能。
